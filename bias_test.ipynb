{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, w, l):\n",
    "        super(Net, self).__init__()\n",
    "        self.w = w\n",
    "        self.l = l\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for item in self.w:\n",
    "            s1, s2, d, b = item\n",
    "            fc = nn.Linear(s1, s2)\n",
    "            fc.weight.data = d\n",
    "            #fc.bias.data = b\n",
    "            self.fc_layers.append(fc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.print_w()\n",
    "        for i in range(len(self.fc_layers)-2):\n",
    "            x = F.relu(self.fc_layers[i](x))\n",
    "        a = F.softmax(F.relu(self.fc_layers[-2](x)), dim=-1)\n",
    "        v = F.relu(self.fc_layers[-1](x))\n",
    "        return a, v\n",
    "\n",
    "    def print_w(self):\n",
    "        for item in self.w:\n",
    "            s1, s2, d, b = item\n",
    "            print(s1, s2, np.shape(d), np.shape(b))\n",
    "        print()\n",
    "        for i, l in enumerate(self.fc_layers):\n",
    "            d = l.weight.data.detach().numpy()\n",
    "            print(\"fc\"+str(i)+\" weights: \", d.shape)\n",
    "            b = l.bias.data.detach().numpy()\n",
    "            print(\"fc\"+str(i)+\" biases: \", b.shape)\n",
    "        print()\n",
    "        \n",
    "    def get_w(self):\n",
    "        w = []\n",
    "        for fc in self.fc_layers:\n",
    "            d = fc.weight.data.detach().numpy()\n",
    "            d = list(np.ravel(d))\n",
    "            w.extend(d)\n",
    "            b = fc.bias.data.detach().numpy()\n",
    "            b = list(np.ravel(b))\n",
    "            w.extend(b)\n",
    "        return w\n",
    "\n",
    "    def set_w(self, w):\n",
    "        self.w = w\n",
    "        for i, item in enumerate(self.w):\n",
    "            s1, s2, d, b = item\n",
    "            self.fc_layers[i].weight.data = d\n",
    "            self.fc_layers[i].bias.data = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = [32,64,32]\n",
    "action_size = 10\n",
    "state_size = 20\n",
    "genome_size = 0\n",
    "genome_size += state_size*hidden_size[0]\n",
    "genome_size += hidden_size[0]\n",
    "if len(hidden_size) > 1:\n",
    "    for i in range(len(hidden_size)):\n",
    "        if i+1 < len(hidden_size):\n",
    "            genome_size += hidden_size[i]*hidden_size[i+1]\n",
    "            bl = max(hidden_size[i], hidden_size[i+1])\n",
    "            genome_size += bl\n",
    "genome_size += action_size*hidden_size[-1]\n",
    "genome_size += hidden_size[-1]\n",
    "genome_size += hidden_size[-1]\n",
    "genome_size += 1\n",
    "print(genome_size)\n",
    "genome = np.random.uniform(-1, 1, genome_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "m1 = 0\n",
    "m2 = state_size * hidden_size[0]\n",
    "m3 = m2 + hidden_size[0]\n",
    "w = torch.Tensor(np.reshape(genome[m1:m2], (hidden_size[0], state_size)))\n",
    "b = torch.Tensor(np.reshape(genome[m2:m3], (hidden_size[0])))\n",
    "weights.append([state_size, hidden_size[0], w, b])\n",
    "if len(hidden_size) > 1:\n",
    "    for i in range(len(hidden_size)):\n",
    "        if i+1 < len(hidden_size):\n",
    "            m1 = m3\n",
    "            m2 = m1 + (hidden_size[i] * hidden_size[i+1])\n",
    "            m3 = m2 + hidden_size[i]\n",
    "            w = torch.Tensor(np.reshape(genome[m1:m2],\n",
    "                             (hidden_size[i+1], hidden_size[i])))\n",
    "            b = torch.Tensor(np.reshape(genome[m2:m3], (hidden_size[i])))\n",
    "            weights.append([hidden_size[i], hidden_size[i+1], w, b])\n",
    "m1 = m3\n",
    "m2 = m1 + action_size*hidden_size[-1]\n",
    "m3 = m2 + action_size\n",
    "w = torch.Tensor(np.reshape(genome[m1:m2], (action_size, hidden_size[-1])))\n",
    "b = torch.Tensor(np.reshape(genome[m2:m3], (action_size)))\n",
    "weights.append([hidden_size[-1], action_size, w, b])\n",
    "m1 = m3\n",
    "m2 = m1 + hidden_size[-1]\n",
    "m3 = m2 + 1\n",
    "w = torch.Tensor(np.reshape(genome[m1:m2], (1, hidden_size[-1])))\n",
    "b = torch.Tensor(np.reshape(genome[m2:m3], (1)))\n",
    "weights.append([hidden_size[-1], 1, w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(weights, True)\n",
    "state = np.random.rand(state_size)\n",
    "state = torch.FloatTensor(state).unsqueeze(0)\n",
    "print(state)\n",
    "a, v = model(state)\n",
    "print(a, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc1 = nn.Linear(40, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 8)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        a = F.softmax(F.relu(self.fc4(x)), dim=-1)\n",
    "        v = F.relu(self.fc5(x))\n",
    "        return a, v\n",
    "\n",
    "    def get_w(self):\n",
    "        layers = [self.fc1, self.fc2, self.fc3, self.fc4, self.fc5]\n",
    "        for i, l in enumerate(layers):\n",
    "            d = l.weight.data.detach().numpy()\n",
    "            print(\"fc\"+str(i)+\" weights: \", d.shape)\n",
    "            b = l.bias.data.detach().numpy()\n",
    "            print(\"fc\"+str(i)+\" biases: \", b.shape)\n",
    "            print()\n",
    "\n",
    "model2 = Net2()\n",
    "_ = model2.get_w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        self.block = [[4, 8], [5, 8], [4, 8]]\n",
    "        self.num_actions = 4\n",
    "        self.num_blocks = len(self.block)\n",
    "        self.inps = [x[0] for x in self.block]\n",
    "        self.out_cat = self.num_blocks * self.num_actions\n",
    "        self.blocks = {}\n",
    "        for index in range(self.num_blocks):\n",
    "            self.blocks[index] = nn.ModuleList()\n",
    "            fc = nn.Linear(self.block[index][0], self.block[index][1])\n",
    "            self.blocks[index].append(fc)\n",
    "            fc = nn.Linear(self.block[index][-1], self.num_actions)\n",
    "            self.blocks[index].append(fc)\n",
    "        self.action = nn.Linear(self.out_cat, self.num_actions)\n",
    "        self.value = nn.Linear(self.out_cat, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        block_out = torch.empty((self.num_blocks, self.num_actions))\n",
    "        current_index = 0\n",
    "        for index in range(len(self.blocks)):\n",
    "            print(current_index)\n",
    "            i = x[0, current_index:current_index+self.inps[index]]\n",
    "            print(i)\n",
    "            a = F.relu(self.blocks[index][0](i))\n",
    "            a = F.relu(self.blocks[index][1](a))\n",
    "            block_out[index] = a\n",
    "            current_index = current_index+self.inps[index]\n",
    "        rc = torch.ravel(torch.tensor(block_out))\n",
    "        a = F.softmax(F.relu(self.action(rc)), dim=-1)\n",
    "        v = F.relu(self.value(rc))\n",
    "        return a, v\n",
    "\n",
    "    def get_w(self):\n",
    "        for index in range(self.num_blocks):\n",
    "            print(\"Block: \" + str(index))\n",
    "            d = self.blocks[index][0].weight.data.detach().numpy()\n",
    "            print(\"fc0 weights: \", d.shape)\n",
    "            b = self.blocks[index][0].bias.data.detach().numpy()\n",
    "            print(\"fc0 biases: \", b.shape)\n",
    "            d = self.blocks[index][1].weight.detach().numpy()\n",
    "            print(\"fc1 weights: \", d.shape)\n",
    "            b = self.blocks[index][1].bias.data.detach().numpy()\n",
    "            print(\"fc1 biases: \", b.shape)\n",
    "        d = self.action.weight.data.detach().numpy()\n",
    "        print(\"action weights: \", d.shape)\n",
    "        b = self.action.bias.data.detach().numpy()\n",
    "        print(\"action biases: \", b.shape)\n",
    "        d = self.value.weight.data.detach().numpy()\n",
    "        print(\"value weights: \", d.shape)\n",
    "        b = self.value.bias.data.detach().numpy()\n",
    "        print(\"value biases: \", b.shape)\n",
    "        print()\n",
    "\n",
    "model3 = Net3()\n",
    "_ = model3.get_w()\n",
    "state = np.random.rand(13)\n",
    "state = torch.FloatTensor(state).unsqueeze(0)\n",
    "a, v = model3(state)\n",
    "print(a, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "action_size = 5 # final output layer\n",
    "genome_size = []\n",
    "net_desc = [[4, 8], [5, 10], [4, 8]]\n",
    "for index in range(len(net_desc)):\n",
    "    net_desc[index].append(action_size)\n",
    "state_size = sum([x[0] for x in net_desc])\n",
    "out_cat = sum([x[-1] for x in net_desc])\n",
    "out_hidden = int(out_cat*0.5)\n",
    "for item in net_desc:\n",
    "    gs = 0\n",
    "    for i in range(len(item)-1):\n",
    "        gs += item[i] * item[i+1]\n",
    "    genome_size.append(gs)\n",
    "cat_hidden = out_cat*out_hidden\n",
    "genome_size.append(cat_hidden)\n",
    "action_head = out_hidden*action_size\n",
    "genome_size.append(action_head)\n",
    "net_desc.append([out_cat, out_hidden])\n",
    "net_desc.append([out_hidden, action_size])\n",
    "value_head = out_hidden*1\n",
    "genome_size.append(value_head)\n",
    "net_desc.append([out_hidden, 1])\n",
    "state = []\n",
    "print(net_desc)\n",
    "for item in genome_size:\n",
    "    state.append(np.random.randint(-1, 1, item))\n",
    "state = np.array(state)\n",
    "print(genome_size)\n",
    "print(sum(genome_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for index, item in enumerate(state):\n",
    "    entry = []\n",
    "    layer_desc = net_desc[index]\n",
    "    if len(layer_desc) > 2:\n",
    "        s1, s2, o = layer_desc\n",
    "        w = torch.Tensor(np.reshape(item[0:s1*s2], (s2, s1)))\n",
    "        entry.append([s1, s2, w])\n",
    "        w = torch.Tensor(np.reshape(item[s1*s2:], (o, s2)))\n",
    "        entry.append([s2, o, w])\n",
    "    else:\n",
    "        s1, o = layer_desc\n",
    "        w = torch.Tensor(np.reshape(item, (o, s1)))\n",
    "        entry.append([s1, o, w])\n",
    "    weights.append(entry)\n",
    "for index, entry in enumerate(weights):\n",
    "    print(\"Entry:\", index)\n",
    "    for e in entry:\n",
    "        print(e[0], e[1], e[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Net4(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(Net4, self).__init__()\n",
    "        self.weights = weights\n",
    "        self.block = []\n",
    "        for item in weights:\n",
    "            if len(item) > 1:\n",
    "                self.block.append([item[0][0], item[0][1], item[1][1]])\n",
    "        print(\"blocks\", self.block)\n",
    "        self.num_actions = self.weights[-2][0][1]\n",
    "        print(\"actions\", self.num_actions)\n",
    "        self.num_blocks = len(self.block)\n",
    "        print(\"num blocks\", self.num_blocks)\n",
    "        self.inps = [x[0] for x in self.block]\n",
    "        print(\"inps\", self.inps)\n",
    "        self.out_cat = sum([x[-1] for x in self.block])\n",
    "        print('out_cat', self.out_cat)\n",
    "        self.out_hidden = self.weights[-3][0][1]\n",
    "        print('out_hidden', self.out_hidden)\n",
    "        self.blocks = {}\n",
    "        for index in range(self.num_blocks):\n",
    "            weights1 = self.weights[index][0][2]\n",
    "            weights2 = self.weights[index][1][2]\n",
    "            self.blocks[index] = nn.ModuleList()\n",
    "            fc = nn.Linear(self.block[index][0], self.block[index][1])\n",
    "            fc.weight.data = weights1\n",
    "            self.blocks[index].append(fc)\n",
    "            fc = nn.Linear(self.block[index][1], self.block[index][2])\n",
    "            fc.weight.data = weights2\n",
    "            self.blocks[index].append(fc)\n",
    "        self.cat_hidden = nn.Linear(self.out_cat, self.out_hidden)\n",
    "        self.cat_hidden.weight.data = self.weights[-3][0][2]\n",
    "        self.action = nn.Linear(self.out_hidden, self.num_actions)\n",
    "        self.action.weight.data = self.weights[-2][0][2]\n",
    "        self.value = nn.Linear(self.out_hidden, 1)\n",
    "        self.value.weight.data = self.weights[-1][0][2]\n",
    "\n",
    " \n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        block_out = torch.empty((self.num_blocks, self.num_actions))\n",
    "        current_index = 0\n",
    "        for index in range(len(self.blocks)):\n",
    "            print(current_index)\n",
    "            i = x[0, current_index:current_index+self.inps[index]]\n",
    "            print(i)\n",
    "            a = F.relu(self.blocks[index][0](i))\n",
    "            a = F.relu(self.blocks[index][1](a))\n",
    "            block_out[index] = a\n",
    "            current_index = current_index+self.inps[index]\n",
    "        rc = torch.ravel(torch.tensor(block_out))\n",
    "        rc = F.relu(self.cat_hidden(rc))\n",
    "        a = F.softmax(F.relu(self.action(rc)), dim=-1)\n",
    "        v = F.relu(self.value(rc))\n",
    "        return a, v\n",
    "\n",
    "    def get_param_count(self, item):\n",
    "        count = 1\n",
    "        for c in item.shape:\n",
    "            count = count * c\n",
    "        return count\n",
    "    \n",
    "    def get_w(self):\n",
    "        total_params = 0\n",
    "        genome = []\n",
    "        for index in range(self.num_blocks):\n",
    "            entry = []\n",
    "            print(\"Block: \" + str(index))\n",
    "            d1 = self.blocks[index][0].weight.data.detach().numpy()\n",
    "            print(\"fc0 weights: \", d1.shape)\n",
    "            total_params += self.get_param_count(d1)\n",
    "            d1 = np.ravel(d1)\n",
    "            entry.extend(list(d1))\n",
    "            b1 = self.blocks[index][0].bias.data.detach().numpy()\n",
    "            print(\"fc0 biases: \", b1.shape)\n",
    "            d2 = self.blocks[index][1].weight.detach().numpy()\n",
    "            print(\"fc1 weights: \", d2.shape)\n",
    "            d2 = np.ravel(d2)\n",
    "            entry.extend(list(d2))\n",
    "            total_params += self.get_param_count(d2)\n",
    "            b2 = self.blocks[index][1].bias.data.detach().numpy()\n",
    "            print(\"fc1 biases: \", b2.shape)\n",
    "            entry = np.ravel(entry)\n",
    "            genome.append(entry)\n",
    "        dc = self.cat_hidden.weight.data.detach().numpy()\n",
    "        genome.append(np.ravel(dc))\n",
    "        total_params += self.get_param_count(dc)\n",
    "        print(\"cat_hidden weights: \", dc.shape)\n",
    "        print(self.weights[-3][0][2].shape)\n",
    "        da = self.action.weight.data.detach().numpy()\n",
    "        genome.append(np.ravel(da))\n",
    "        total_params += self.get_param_count(da)\n",
    "        print(\"action weights: \", da.shape)\n",
    "        print(self.weights[-2][0][2].shape)\n",
    "        ba = self.action.bias.data.detach().numpy()\n",
    "        print(\"action biases: \", ba.shape)\n",
    "        dv = self.value.weight.data.detach().numpy()\n",
    "        genome.append(np.ravel(dv))\n",
    "        total_params += self.get_param_count(dv)\n",
    "        print(\"value weights: \", dv.shape)\n",
    "        print(self.weights[-1][0][2].shape)\n",
    "        bv = self.value.bias.data.detach().numpy()\n",
    "        print(\"value biases: \", bv.shape)\n",
    "        print(\"total params: \", total_params)\n",
    "        genome_shape = [len(x) for x in genome]\n",
    "        print(genome_shape)\n",
    "        print()\n",
    "\n",
    "model4 = Net4(weights)\n",
    "_ = model4.get_w()\n",
    "state = np.random.rand(4 + 5 + 4)\n",
    "state = torch.FloatTensor(state).unsqueeze(0)\n",
    "print(state)\n",
    "a, v = model4(state)\n",
    "print(a, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "action_size = 5 # final output layer\n",
    "obs = [4, 5, 6]\n",
    "prev_states = 6\n",
    "genome_size = []\n",
    "net_desc = []\n",
    "\n",
    "for item in obs:\n",
    "    entry = [prev_states, item, item*2, action_size]\n",
    "    net_desc.append(entry)\n",
    "print(net_desc)\n",
    "\n",
    "genome_size = []\n",
    "for item in net_desc:\n",
    "    p, inps, hidden, outs = item\n",
    "    prev_states = p\n",
    "    for depth in range(prev_states):\n",
    "        for width in range(p):\n",
    "            size = 0\n",
    "            if depth == 0:\n",
    "                size += inps*hidden\n",
    "            else:\n",
    "                size += 2*outs*hidden\n",
    "            size += hidden*outs\n",
    "            genome_size.append(size)\n",
    "        p -= 1\n",
    "print(net_desc)\n",
    "print(genome_size)\n",
    "out_cat = len(obs) * action_size\n",
    "out_hidden = action_size*2\n",
    "cat_hidden = out_cat*out_hidden\n",
    "genome_size.append(cat_hidden)\n",
    "action_head = out_hidden*action_size\n",
    "genome_size.append(action_head)\n",
    "net_desc.append([out_cat, out_hidden])\n",
    "net_desc.append([out_hidden, action_size])\n",
    "value_head = out_hidden*1\n",
    "genome_size.append(value_head)\n",
    "net_desc.append([out_hidden, 1])\n",
    "\n",
    "\n",
    "state = []\n",
    "for item in genome_size:\n",
    "    state.append(np.random.randint(-1, 1, item))\n",
    "state = np.array(state)\n",
    "print(net_desc)\n",
    "print(genome_size)\n",
    "print(sum(genome_size))\n",
    "\n",
    "weights = []\n",
    "state_index = 0\n",
    "b = 0\n",
    "for index, layer_desc in enumerate(net_desc):\n",
    "    entry = []\n",
    "    if len(layer_desc) > 2:\n",
    "        p, s1, s2, o = layer_desc\n",
    "        prev_states = p\n",
    "        for depth in range(prev_states):\n",
    "            for width in range(p):\n",
    "                item = state[state_index]\n",
    "                sn = s1\n",
    "                if depth > 0:\n",
    "                    sn = o * 2\n",
    "                w = torch.Tensor(np.reshape(item[0:sn*s2], (s2, sn)))\n",
    "                entry.append([b, depth, width, sn, s2, w])\n",
    "                w = torch.Tensor(np.reshape(item[sn*s2:], (o, s2)))\n",
    "                entry.append([b, depth, width, s2, o, w])\n",
    "                state_index += 1\n",
    "            p -= 1\n",
    "        b += 1\n",
    "    else:\n",
    "        item = state[state_index]\n",
    "        s1, o = layer_desc\n",
    "        w = torch.Tensor(np.reshape(item, (o, s1)))\n",
    "        entry.append([s1, o, w])\n",
    "        state_index += 1\n",
    "    weights.append(entry)\n",
    "for index, entry in enumerate(weights):\n",
    "    print(\"Entry:\", index)\n",
    "    for e in entry:\n",
    "        if len(e) > 3:\n",
    "            print(e[0], e[1], e[2], e[3], e[4], e[5].shape)\n",
    "        else:\n",
    "            print(e[0], e[1], e[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class Net5(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(Net5, self).__init__()\n",
    "        self.weights = weights\n",
    "        self.inp_blocks = {}\n",
    "        for entry in self.weights:\n",
    "            for item in entry:\n",
    "                if len(item) > 3:\n",
    "                    block = item[0]\n",
    "                    depth = item[1]\n",
    "                    order = item[2]\n",
    "                    s1 = item[3]\n",
    "                    s2 = item[4]\n",
    "                    w = item[5]\n",
    "                    if block not in self.inp_blocks:\n",
    "                        self.inp_blocks[block] = {}\n",
    "                    if depth not in self.inp_blocks[block]:\n",
    "                        self.inp_blocks[block][depth] = {}\n",
    "                    if order not in self.inp_blocks[block][depth]:\n",
    "                        self.inp_blocks[block][depth][order] = []\n",
    "                    self.inp_blocks[block][depth][order].append([s1, s2, w])\n",
    "        self.block_inputs = []\n",
    "        for entry in self.weights:\n",
    "            if len(entry[0]) > 3:\n",
    "                self.block_inputs.append(entry[0][3])\n",
    "        print(\"block inputs\", self.block_inputs)\n",
    "        self.num_actions = self.weights[-2][0][1]\n",
    "        print(\"actions\", self.num_actions)\n",
    "        self.num_blocks = len(self.inp_blocks)\n",
    "        print(\"num blocks\", self.num_blocks)\n",
    "        self.prev_states = len(self.inp_blocks[0])\n",
    "        print(\"prev states\", self.prev_states)\n",
    "        self.out_cat = self.num_blocks * self.num_actions\n",
    "        print('out_cat', self.out_cat)\n",
    "        self.out_hidden = self.weights[-3][0][1]\n",
    "        print('out_hidden', self.out_hidden)\n",
    "        self.neurons = nn.ModuleList()\n",
    "        for bi, block in self.inp_blocks.items():\n",
    "            for di, dblock in block.items():\n",
    "                for oi, oblock in dblock.items():\n",
    "                    for item in oblock:\n",
    "                        s1 = item[0]\n",
    "                        s2 = item[1]\n",
    "                        weights = item[2]\n",
    "                        fc = nn.Linear(s1, s2)\n",
    "                        fc.weight.data = weights\n",
    "                        self.neurons.append(fc)\n",
    "        self.cat_hidden = nn.Linear(self.out_cat, self.out_hidden)\n",
    "        self.cat_hidden.weight.data = self.weights[-3][0][2]\n",
    "        self.action = nn.Linear(self.out_hidden, self.num_actions)\n",
    "        self.action.weight.data = self.weights[-2][0][2]\n",
    "        self.value = nn.Linear(self.out_hidden, 1)\n",
    "        self.value.weight.data = self.weights[-1][0][2]\n",
    " \n",
    "    def forward(self, x):\n",
    "        #print(\"forward\")\n",
    "        block_out = torch.empty((self.num_blocks, self.num_actions))\n",
    "        neuron_index = 0\n",
    "        input_index = 0\n",
    "        for bi, block in self.inp_blocks.items():\n",
    "            binps = self.block_inputs[bi]\n",
    "            i1 = input_index\n",
    "            i2 = input_index + (self.block_inputs[bi]*self.prev_states)\n",
    "            x1 = x[0][i1:i2]\n",
    "            prev_outs = []\n",
    "            out_index = 0\n",
    "            last_out = None\n",
    "            for di, dblock in block.items():\n",
    "                if di == 0:\n",
    "                    for oi, oblock in dblock.items():\n",
    "                        inp = x1[oi*binps:(oi*binps)+binps]\n",
    "                        out = F.relu(self.neurons[neuron_index](inp))\n",
    "                        neuron_index += 1\n",
    "                        out = F.relu(self.neurons[neuron_index](out))\n",
    "                        last_out = out\n",
    "                        prev_outs.append(out)\n",
    "                        neuron_index += 1\n",
    "                else:\n",
    "                    for oi, oblock in dblock.items():\n",
    "                        inp = torch.cat((prev_outs[out_index], prev_outs[out_index+1]))\n",
    "                        out_index += 1\n",
    "                        out = F.relu(self.neurons[neuron_index](inp))\n",
    "                        neuron_index += 1\n",
    "                        out = F.relu(self.neurons[neuron_index](out))\n",
    "                        last_out = out\n",
    "                        prev_outs.append(out)\n",
    "                        neuron_index += 1\n",
    "            block_out[bi] = last_out\n",
    "            input_index += self.block_inputs[bi]*self.prev_states\n",
    "        rc = torch.ravel(torch.tensor(block_out))\n",
    "        rc = F.relu(self.cat_hidden(rc))\n",
    "        a = F.softmax(F.relu(self.action(rc)), dim=-1)\n",
    "        v = F.relu(self.value(rc))\n",
    "        return a, v\n",
    "\n",
    "    def get_param_count(self, item):\n",
    "        count = 1\n",
    "        for c in item.shape:\n",
    "            count = count * c\n",
    "        return count\n",
    "\n",
    "    def get_w(self):\n",
    "        total_params = 0\n",
    "        genome = []\n",
    "        neuron_index = 0\n",
    "        while neuron_index < len(self.neurons):\n",
    "            entry = []\n",
    "            print(\"Block: \" + str(index))\n",
    "            d1 = self.neurons[neuron_index].weight.data.detach().numpy()\n",
    "            neuron_index += 1\n",
    "            print(\"fc0 weights: \", d1.shape)\n",
    "            total_params += self.get_param_count(d1)\n",
    "            d1 = np.ravel(d1)\n",
    "            entry.extend(list(d1))\n",
    "            d2 = self.neurons[neuron_index].weight.data.detach().numpy()\n",
    "            neuron_index += 1\n",
    "            print(\"fc1 weights: \", d2.shape)\n",
    "            d2 = np.ravel(d2)\n",
    "            entry.extend(list(d2))\n",
    "            total_params += self.get_param_count(d2)\n",
    "            entry = np.ravel(entry)\n",
    "            genome.append(entry)\n",
    "        dc = self.cat_hidden.weight.data.detach().numpy()\n",
    "        genome.append(np.ravel(dc))\n",
    "        total_params += self.get_param_count(dc)\n",
    "        print(\"cat_hidden weights: \", dc.shape)\n",
    "        print(self.weights[-3][0][2].shape)\n",
    "        da = self.action.weight.data.detach().numpy()\n",
    "        genome.append(np.ravel(da))\n",
    "        total_params += self.get_param_count(da)\n",
    "        print(\"action weights: \", da.shape)\n",
    "        print(self.weights[-2][0][2].shape)\n",
    "        ba = self.action.bias.data.detach().numpy()\n",
    "        print(\"action biases: \", ba.shape)\n",
    "        dv = self.value.weight.data.detach().numpy()\n",
    "        genome.append(np.ravel(dv))\n",
    "        total_params += self.get_param_count(dv)\n",
    "        print(\"value weights: \", dv.shape)\n",
    "        print(self.weights[-1][0][2].shape)\n",
    "        bv = self.value.bias.data.detach().numpy()\n",
    "        print(\"value biases: \", bv.shape)\n",
    "        print(\"total params: \", total_params)\n",
    "        genome_shape = [len(x) for x in genome]\n",
    "        print(genome_shape)\n",
    "        print()\n",
    "\n",
    "model5 = Net5(weights)\n",
    "print(\"Done\")\n",
    "_ = model5.get_w()\n",
    "for _ in range(1000):\n",
    "    state = np.random.rand(4*prev_states + 5*prev_states + 6*prev_states)\n",
    "    state = torch.FloatTensor(state).unsqueeze(0)\n",
    "    #print(state)\n",
    "    a, v = model5(state)\n",
    "    #print(a, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
