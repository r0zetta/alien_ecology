{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, w, l):\n",
    "        super(Net, self).__init__()\n",
    "        self.w = w\n",
    "        self.l = l\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for item in self.w:\n",
    "            s1, s2, d, b = item\n",
    "            fc = nn.Linear(s1, s2)\n",
    "            fc.weight.data = d\n",
    "            #fc.bias.data = b\n",
    "            self.fc_layers.append(fc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.print_w()\n",
    "        for i in range(len(self.fc_layers)-2):\n",
    "            x = F.relu(self.fc_layers[i](x))\n",
    "        a = F.softmax(F.relu(self.fc_layers[-2](x)), dim=-1)\n",
    "        v = F.relu(self.fc_layers[-1](x))\n",
    "        return a, v\n",
    "\n",
    "    def print_w(self):\n",
    "        for item in self.w:\n",
    "            s1, s2, d, b = item\n",
    "            print(s1, s2, np.shape(d), np.shape(b))\n",
    "        print()\n",
    "        for i, l in enumerate(self.fc_layers):\n",
    "            d = l.weight.data.detach().numpy()\n",
    "            print(\"fc\"+str(i)+\" weights: \", d.shape)\n",
    "            b = l.bias.data.detach().numpy()\n",
    "            print(\"fc\"+str(i)+\" biases: \", b.shape)\n",
    "        print()\n",
    "        \n",
    "    def get_w(self):\n",
    "        w = []\n",
    "        for fc in self.fc_layers:\n",
    "            d = fc.weight.data.detach().numpy()\n",
    "            d = list(np.ravel(d))\n",
    "            w.extend(d)\n",
    "            b = fc.bias.data.detach().numpy()\n",
    "            b = list(np.ravel(b))\n",
    "            w.extend(b)\n",
    "        return w\n",
    "\n",
    "    def set_w(self, w):\n",
    "        self.w = w\n",
    "        for i, item in enumerate(self.w):\n",
    "            s1, s2, d, b = item\n",
    "            self.fc_layers[i].weight.data = d\n",
    "            self.fc_layers[i].bias.data = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = [32,64,32]\n",
    "action_size = 10\n",
    "state_size = 20\n",
    "genome_size = 0\n",
    "genome_size += state_size*hidden_size[0]\n",
    "genome_size += hidden_size[0]\n",
    "if len(hidden_size) > 1:\n",
    "    for i in range(len(hidden_size)):\n",
    "        if i+1 < len(hidden_size):\n",
    "            genome_size += hidden_size[i]*hidden_size[i+1]\n",
    "            bl = max(hidden_size[i], hidden_size[i+1])\n",
    "            genome_size += bl\n",
    "genome_size += action_size*hidden_size[-1]\n",
    "genome_size += hidden_size[-1]\n",
    "genome_size += hidden_size[-1]\n",
    "genome_size += 1\n",
    "print(genome_size)\n",
    "genome = np.random.uniform(-1, 1, genome_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "m1 = 0\n",
    "m2 = state_size * hidden_size[0]\n",
    "m3 = m2 + hidden_size[0]\n",
    "w = torch.Tensor(np.reshape(genome[m1:m2], (hidden_size[0], state_size)))\n",
    "b = torch.Tensor(np.reshape(genome[m2:m3], (hidden_size[0])))\n",
    "weights.append([state_size, hidden_size[0], w, b])\n",
    "if len(hidden_size) > 1:\n",
    "    for i in range(len(hidden_size)):\n",
    "        if i+1 < len(hidden_size):\n",
    "            m1 = m3\n",
    "            m2 = m1 + (hidden_size[i] * hidden_size[i+1])\n",
    "            m3 = m2 + hidden_size[i]\n",
    "            w = torch.Tensor(np.reshape(genome[m1:m2],\n",
    "                             (hidden_size[i+1], hidden_size[i])))\n",
    "            b = torch.Tensor(np.reshape(genome[m2:m3], (hidden_size[i])))\n",
    "            weights.append([hidden_size[i], hidden_size[i+1], w, b])\n",
    "m1 = m3\n",
    "m2 = m1 + action_size*hidden_size[-1]\n",
    "m3 = m2 + action_size\n",
    "w = torch.Tensor(np.reshape(genome[m1:m2], (action_size, hidden_size[-1])))\n",
    "b = torch.Tensor(np.reshape(genome[m2:m3], (action_size)))\n",
    "weights.append([hidden_size[-1], action_size, w, b])\n",
    "m1 = m3\n",
    "m2 = m1 + hidden_size[-1]\n",
    "m3 = m2 + 1\n",
    "w = torch.Tensor(np.reshape(genome[m1:m2], (1, hidden_size[-1])))\n",
    "b = torch.Tensor(np.reshape(genome[m2:m3], (1)))\n",
    "weights.append([hidden_size[-1], 1, w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(weights, True)\n",
    "state = np.random.rand(state_size)\n",
    "state = torch.FloatTensor(state).unsqueeze(0)\n",
    "print(state)\n",
    "a, v = model(state)\n",
    "print(a, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc1 = nn.Linear(40, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 8)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        a = F.softmax(F.relu(self.fc4(x)), dim=-1)\n",
    "        v = F.relu(self.fc5(x))\n",
    "        return a, v\n",
    "\n",
    "    def get_w(self):\n",
    "        layers = [self.fc1, self.fc2, self.fc3, self.fc4, self.fc5]\n",
    "        for i, l in enumerate(layers):\n",
    "            d = l.weight.data.detach().numpy()\n",
    "            print(\"fc\"+str(i)+\" weights: \", d.shape)\n",
    "            b = l.bias.data.detach().numpy()\n",
    "            print(\"fc\"+str(i)+\" biases: \", b.shape)\n",
    "            print()\n",
    "\n",
    "model2 = Net2()\n",
    "_ = model2.get_w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        self.block = [[4, 8], [5, 8], [4, 8]]\n",
    "        self.num_actions = 4\n",
    "        self.num_blocks = len(self.block)\n",
    "        self.inps = [x[0] for x in self.block]\n",
    "        self.out_cat = self.num_blocks * self.num_actions\n",
    "        self.blocks = {}\n",
    "        for index in range(self.num_blocks):\n",
    "            self.blocks[index] = nn.ModuleList()\n",
    "            fc = nn.Linear(self.block[index][0], self.block[index][1])\n",
    "            self.blocks[index].append(fc)\n",
    "            fc = nn.Linear(self.block[index][-1], self.num_actions)\n",
    "            self.blocks[index].append(fc)\n",
    "        self.action = nn.Linear(self.out_cat, self.num_actions)\n",
    "        self.value = nn.Linear(self.out_cat, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        block_out = torch.empty((self.num_blocks, self.num_actions))\n",
    "        current_index = 0\n",
    "        for index in range(len(self.blocks)):\n",
    "            print(current_index)\n",
    "            i = x[0, current_index:current_index+self.inps[index]]\n",
    "            print(i)\n",
    "            a = F.relu(self.blocks[index][0](i))\n",
    "            a = F.relu(self.blocks[index][1](a))\n",
    "            block_out[index] = a\n",
    "            current_index = current_index+self.inps[index]\n",
    "        rc = torch.ravel(torch.tensor(block_out))\n",
    "        a = F.softmax(F.relu(self.action(rc)), dim=-1)\n",
    "        v = F.relu(self.value(rc))\n",
    "        return a, v\n",
    "\n",
    "    def get_w(self):\n",
    "        for index in range(self.num_blocks):\n",
    "            print(\"Block: \" + str(index))\n",
    "            d = self.blocks[index][0].weight.data.detach().numpy()\n",
    "            print(\"fc0 weights: \", d.shape)\n",
    "            b = self.blocks[index][0].bias.data.detach().numpy()\n",
    "            print(\"fc0 biases: \", b.shape)\n",
    "            d = self.blocks[index][1].weight.detach().numpy()\n",
    "            print(\"fc1 weights: \", d.shape)\n",
    "            b = self.blocks[index][1].bias.data.detach().numpy()\n",
    "            print(\"fc1 biases: \", b.shape)\n",
    "        d = self.action.weight.data.detach().numpy()\n",
    "        print(\"action weights: \", d.shape)\n",
    "        b = self.action.bias.data.detach().numpy()\n",
    "        print(\"action biases: \", b.shape)\n",
    "        d = self.value.weight.data.detach().numpy()\n",
    "        print(\"value weights: \", d.shape)\n",
    "        b = self.value.bias.data.detach().numpy()\n",
    "        print(\"value biases: \", b.shape)\n",
    "        print()\n",
    "\n",
    "model3 = Net3()\n",
    "_ = model3.get_w()\n",
    "state = np.random.rand(13)\n",
    "state = torch.FloatTensor(state).unsqueeze(0)\n",
    "a, v = model3(state)\n",
    "print(a, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "action_size = 4 # final output layer\n",
    "genome_size = []\n",
    "net_desc = [[4, 8], [5, 10], [4, 8]]\n",
    "for index in range(len(net_desc)):\n",
    "    net_desc[index].append(action_size)\n",
    "state_size = sum([x[0] for x in net_desc])\n",
    "out_cat = sum([x[-1] for x in net_desc])\n",
    "for item in net_desc:\n",
    "    gs = 0\n",
    "    for i in range(len(item)-1):\n",
    "        gs += item[i] * item[i+1]\n",
    "    genome_size.append(gs)\n",
    "action_head = out_cat*action_size\n",
    "genome_size.append(action_head)\n",
    "net_desc.append([out_cat, action_size])\n",
    "value_head = out_cat*1\n",
    "genome_size.append(value_head)\n",
    "net_desc.append([out_cat, 1])\n",
    "state = []\n",
    "for item in genome_size:\n",
    "    state.append(np.random.randint(-1, 2, item))\n",
    "state = np.array(state)\n",
    "print(genome_size)\n",
    "print(sum(genome_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for index, item in enumerate(state):\n",
    "    entry = []\n",
    "    layer_desc = net_desc[index]\n",
    "    if len(layer_desc) > 2:\n",
    "        s1, s2, o = layer_desc\n",
    "        w = torch.Tensor(np.reshape(item[0:s1*s2], (s2, s1)))\n",
    "        entry.append([s1, s2, w])\n",
    "        w = torch.Tensor(np.reshape(item[s1*s2:], (o, s2)))\n",
    "        entry.append([s2, o, w])\n",
    "    else:\n",
    "        s1, o = layer_desc\n",
    "        w = torch.Tensor(np.reshape(item, (o, s1)))\n",
    "        entry.append([s1, o, w])\n",
    "    weights.append(entry)\n",
    "for index, entry in enumerate(weights):\n",
    "    print(\"Entry:\", index)\n",
    "    for e in entry:\n",
    "        print(e[0], e[1], e[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Net4(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(Net4, self).__init__()\n",
    "        self.weights = weights\n",
    "        self.block = []\n",
    "        for item in weights:\n",
    "            if len(item) > 1:\n",
    "                self.block.append([item[0][0], item[0][1], item[1][1]])\n",
    "        print(\"blocks\", self.block)\n",
    "        self.num_actions = self.weights[-2][0][1]\n",
    "        print(\"actions\", self.num_actions)\n",
    "        self.num_blocks = len(self.block)\n",
    "        print(\"num blocks\", self.num_blocks)\n",
    "        self.inps = [x[0] for x in self.block]\n",
    "        print(\"inps\", self.inps)\n",
    "        self.out_cat = sum([x[-1] for x in self.block])\n",
    "        print(self.out_cat)\n",
    "        self.blocks = {}\n",
    "        for index in range(self.num_blocks):\n",
    "            weights1 = self.weights[index][0][2]\n",
    "            weights2 = self.weights[index][1][2]\n",
    "            self.blocks[index] = nn.ModuleList()\n",
    "            fc = nn.Linear(self.block[index][0], self.block[index][1])\n",
    "            fc.weight.data = weights1\n",
    "            self.blocks[index].append(fc)\n",
    "            fc = nn.Linear(self.block[index][1], self.block[index][2])\n",
    "            fc.weight.data = weights2\n",
    "            self.blocks[index].append(fc)\n",
    "        self.action = nn.Linear(self.out_cat, self.num_actions)\n",
    "        self.value = nn.Linear(self.out_cat, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        block_out = torch.empty((self.num_blocks, self.num_actions))\n",
    "        current_index = 0\n",
    "        for index in range(len(self.blocks)):\n",
    "            print(current_index)\n",
    "            i = x[0, current_index:current_index+self.inps[index]]\n",
    "            print(i)\n",
    "            a = F.relu(self.blocks[index][0](i))\n",
    "            a = F.relu(self.blocks[index][1](a))\n",
    "            block_out[index] = a\n",
    "            current_index = current_index+self.inps[index]\n",
    "        rc = torch.ravel(torch.tensor(block_out))\n",
    "        a = F.softmax(F.relu(self.action(rc)), dim=-1)\n",
    "        v = F.relu(self.value(rc))\n",
    "        return a, v\n",
    "\n",
    "    def get_param_count(self, item):\n",
    "        count = 1\n",
    "        for c in item.shape:\n",
    "            count = count * c\n",
    "        return count\n",
    "    \n",
    "    def get_w(self):\n",
    "        total_params = 0\n",
    "        for index in range(self.num_blocks):\n",
    "            print(\"Block: \" + str(index))\n",
    "            d = self.blocks[index][0].weight.data.detach().numpy()\n",
    "            print(\"fc0 weights: \", d.shape)\n",
    "            total_params += self.get_param_count(d)\n",
    "            b = self.blocks[index][0].bias.data.detach().numpy()\n",
    "            print(\"fc0 biases: \", b.shape)\n",
    "            d = self.blocks[index][1].weight.detach().numpy()\n",
    "            total_params += self.get_param_count(d)\n",
    "            print(\"fc1 weights: \", d.shape)\n",
    "            b = self.blocks[index][1].bias.data.detach().numpy()\n",
    "            print(\"fc1 biases: \", b.shape)\n",
    "        d = self.action.weight.data.detach().numpy()\n",
    "        total_params += self.get_param_count(d)\n",
    "        print(\"action weights: \", d.shape)\n",
    "        b = self.action.bias.data.detach().numpy()\n",
    "        print(\"action biases: \", b.shape)\n",
    "        d = self.value.weight.data.detach().numpy()\n",
    "        total_params += self.get_param_count(d)\n",
    "        print(\"value weights: \", d.shape)\n",
    "        b = self.value.bias.data.detach().numpy()\n",
    "        print(\"value biases: \", b.shape)\n",
    "        print(\"total params: \", total_params)\n",
    "        print()\n",
    "\n",
    "model4 = Net4(weights)\n",
    "_ = model4.get_w()\n",
    "state = np.random.rand(4 + 5 + 4 + 6)\n",
    "state = torch.FloatTensor(state).unsqueeze(0)\n",
    "print(state)\n",
    "a, v = model4(state)\n",
    "print(a, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
